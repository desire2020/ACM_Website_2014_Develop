---
year:		2016
category:	academic_festival
---

###一、校友专场
1.
**主题报告**：让机器睁开眼

**报告人**：朱珑（依图科技创始人、CEO）

**概要**：机器视觉学科从MARR开创到现在已有近40年，在物体识别、三维重建、运动跟踪等视觉任务上建立起基础的理论框架。过去10年，体感游戏、辅助驾驶、人脸识别等领域的应用突破已使大众广泛受益。机器的人脸识别识别水平已经大大超过人类，对机器智能的理解和探索人脑极限都很有启发性意义。随着感知设备的普及、高性能计算能力的提升以及机器学习算法的革新，将把视觉理解带向更广泛的领域。这个讲座我们简单回顾机器视觉的重要工作以及正在进行的变革。

**简历**：朱珑，加州大学洛杉矶分校统计学博士，师从Alan Yuille教授（艾伦·龙尔，计算机视觉学界奠基人之一），从事计算机视觉的统计建模和计算的研究。之后他在麻省理工学院人工智能实验室担任博士后研究员。而在纽约大学Courant数学研究所担任研究员期间，他获得过国际计算机视觉算法竞赛“图像目标检测”项目冠军。

2.
**主题报告**：无人驾驶的技术与挑战

**报告人**：薛贵荣（天壤智能创始人、CEO）

**摘要**：从统计上来说，汽车上最不可靠的部分是驾驶员，无人驾驶将从根本上去解决这个问题。本报告将从汽车的演变开始，介绍今天的汽车安全等方面的知识，接下来会介绍ADAS系统和无人驾驶的核心技术，包括高精度地图、汽车感知和决策控制系统三个核心的模块所解决的问题与算法。接下来将进一步介绍今天的无人驾驶所面临的技术问题和社会挑战，以及我们的机遇。

**简历**：薛贵荣，原阿里巴巴旗下阿里妈妈大数据中心负责人，阿里妈妈首席数据科学家，负责研发了阿里搜索引擎、反作弊、DMP平台、展示营销技术平台等。研究方向主要为机器学习、互联网搜索、大数据营销等，在国际会议和国际期刊发表论文70多篇。在此之前曾经任职于上海交通大学计算机系。担任国家科技部云计算专家组成员、北航软件学院大数据专业的特聘教授。曾获得中国计算机学会评选的全国优秀博士论文奖（2006年）、全国百篇优博提名奖（2009年）。2006年于上海交通大学获得博士学位
。

3.
**主题报告**: Compiled Inference for Probabilistic Programs

**报告人**：李磊（今日头条科学家）

**Abstract**: What is the right representation for AI? Probabilistic programing provides one promising direction. In this talk, we will give a brief introduction to BLOG, a probabilistic programming language that combines the power of first-order logic and probability. A probabilistic program defines a probability measure over its semantic structures. One common goal of probabilistic programming languages (PPLs) is to compute posterior probabilities for arbitrary models and queries, given observed evidence, using a generic inference engine. Most PPL inference engines—even the compiled ones—incur significant runtime interpretation overhead, especially for contingent and open-universe models. This paper describes Swift, a compiler for the BLOG PPL. Swift-generated code incorporates optimizations that eliminate interpretation overhead, maintain dynamic dependencies efficiently, and handle memory management for possible worlds of varying sizes. Experiments comparing Swift with other PPL engines on a variety of inference problems demonstrate speedups ranging from 12x to 326x.

**简历**：李磊，原百度美国深度学习实验室少帅科学家 。上海交通大学计算机系ACM班2002级本科， 卡耐基梅隆大学计算机系博士。曾在加州大学伯克利分校作博士后研究。 美国计算机学会数据挖掘委员会SIGKDD最佳博士论文第二名。曾先后短期任职于微软研究院、Google、IBM TJ Waston研究中心。

4.
**主题报告**：大规模机器学习平台简介

**报告人**：杨博海（第四范式产品架构师）

**概要**：作为人工智能领域的核心技术方向，基于大数据的机器学习散发在科研和业界发挥着举足轻重的作用。报告将会就大规模机器学习算法原理、算法并行化实现方式、大规模机器学习平台发展和演进历程进行详细介绍。

**简历**：杨博海，上海交通大学计算机系2004级本科、2004-2005年度ACM国际大学生程序设计竞赛世界冠军。曾任百度凤巢机器学习平台负责人，百度资深大规模机器学习架构和算法专家，“个性化”推荐引擎模型、算法专家，大幅提高业务变现能力，百度最好将团队成员。

###二、在校学生专场
1.
**Title**: Counting with Markov Chain

**报告人**：张弛豪（上海交通大学计算机系博士生）

**Abstract**: In this talk, I will introduce the basic idea of Markov chain Monte Carlo (MCMC) method for sampling and counting combinatorial objects. I will demonstrate the use of coupling technique to bound the mixing time of Markov chains. The running example of the talk is the problem of counting proper q-colorings. I will survey some classic results and recent progress of the problem.

**Bio**: Chihao Zhang graduated from ACM05 in 2009 and is now a PhD student in SJTU. His research interest is theoretical computer science. Currently, he mainly works on approximate counting algorithms.

2.
**Title**: Improved Efficiency Guarantees in Auctions with Budgets

**报告人**：肖涛（上海交通大学计算机系博士生）

**Abstract**: We study the efficiency guarantees in the simple auction environment where the auctioneer has one unit of divisible good to be distributed among a number of budget constrained agents. With budget constraints, the social welfare cannot be approximated by a better factor than the number of agents by any truthful mechanism. Thus, we follow a recent work by Dobzinski and Leme [ICALP 2014] to approximate the liquid welfare, which is the welfare of the agents each capped by her/his own budget. We design a new truthful auction with an approximation ratio of approximately 1.618, improving the best previous ratio of 2 when the budgets for agents are public knowledge and their valuation is linear (additive). In private budget setting, we propose the first constant approximation auction with approximation ratio of 34. Moreover, this auction works for any valuation function. Previously, only O(log(n)) approximation was known for linear and decreasing marginal (concave) valuations, and O(log^2(n)) approximation was known for sub-additive valuations.

**Bio**: Tao Xiao is now a third year Ph.D student in SJTU, supervised by Prof. Xiaotie Deng. His research interest lies theoretical computer science, especially in Mechanism Design. Before that, Tao got his bachelor's degree also in SJTU (ACM Honored Class).

3.
**Title**: Exploiting LSTM Structure in Deep Neural Networks for Speech Recognition

**报告人**：贺天行（上海交通大学计算机系硕士生）

**Abstract**: The CD-DNN-HMM system has became the state-of-art system for large vocabulary continuous speech recognition (LVCSR) tasks, in which deep neural networks (DNN) plays a key role. However, DNN training suffers from the van-ishing gradient problem, limiting training of deep models. In this work, we address this problem by incorporating the successful long-short term memory (LSTM) structure, which has been proposed to help recurrent neural network (RNN) to remember long term dependencies, into DNN. Also, we propose a generalized formulation of the LSTM block, which we name general LSTM(GLSTM). In our experiments, it is shown that our proposed (G)LSTM-DNN scales well with more layers, and achieves 8.2% relative word error rate reduction on the 2000-hour Switchboard data set.

**Bio**: In 2013 I began working in Kai Yu’s speech lab in SJTU, dedicated to improve the performance of automatic speech recognition. My current focus is on the language model part. Apart from working in speech, I’m also interested in the developments in NLP and machine learning.

4.
**Title**: Wishart Mechanism for Differentially Private Principle Components Analysis

**报告人**：蒋伍轩（上海交通大学计算机系硕士生）

**Abstract**: We propose a new input perturbation mechanism for publishing a covariance matrix to achieve (\epsilon,0)-differential privacy. Our mechanism uses a Wishart distribution to generate matrix noise. We particularly apply this mechanism to principle component analysis. Our mechanism is able to keep the positive semidefiniteness of the published covariance matrix. Thus, our approach gives rise to a general publishing framework for input perturbation of a symmetric positive semidefinite matrix. Moreover, compared with the classic Laplace mechanism, our method has better utility guarantee. To the best of our knowledge,Wishart mechanism is the best input perturbation approach for (\varepsilon,0)-differentially private PCA. We also compare our work with previous exponential mechanism algorithms in the literature and provide near optimal bound while having more flexibility and less computational intractability.

**Bio**: I'm a second-year master of philosophy from Learning and Optimization Group, supervised by professor Zhihua Zhang. My current research interests include machine learning, sketching, differential privacy and online learning.

5.
**Title**: Online Packing

**报告人**：吉梓玮（上海交通大学ACM班大四）

**Abstract**: In this project, we consider the online version of the classical packing problem, where at each time step one column of the constraint matrix is revealed, together with the corresponding coefficient of the objective function. Then the online algorithm needs to choose a value for the corresponding variable, which cannot be revoked. The online packing problem has many applications. We can use it to solve the online routing problem, the online matching problem, the online Adwords problem, etc. The random-arrival model is adopted, and we use the primal-dual method and multiplicative weight update method in our algorithm. Our algorithm is near-optimal, and the assumptions we made are necessary.

**Bio**: Ziwei Ji (ACM Class 2012) is an intern at the AIMS Lab supervised by Prof. Xiaotie Deng. His main interest lies in theoretical computer science.

6.
**Title**: Wander Join: Online Aggregation via Random Walks

**报告人**：赵卓越（上海交通大学ACM班大四）

**Abstract**: Joins are expensive, and online aggregation over joins was proposed to mitigate the cost, which offers users a nice and flexible tradeoff between query efficiency and accuracy in a continuous, online fashion. However, the state-of-the-art approach, in both internal and external memory, is based on ripple join, which is still very expensive and even needs unrealistic assumptions (e.g., tuples in a table are stored in random order). This work proposes a new approach, the wander join algorithm, to the online aggregation problem by performing random walks without having to collect any statistics a priori. Compared with ripple join, wander join is particularly efficient for equality joins involving multiple tables, but also supports -joins. Selection predicates and group-by clauses can be handled as well. Extensive experiements using the TPC-H benchmark have demonstrated the superior performance of wander join over ripple join in the latest version of PostgreSQL, demonstrating its practicality in a full-fledged database system.

**Bio**: Zhuoyue Zhao is an undergraduate student at ACM Class, Shanghai Jiao Tong University. His research interest is focused on large-scale data management systems. Starting from fall 2016, he will be a PhD student advised by Prof. Feifei Li at University of Utah.

7.
**Title**: Paragraph Vector Based Topic Model for Language Model Adaptation

**报告人**：金汶功（上海交通大学ACM班大四）

**Abstract**: Topic model is an important approach for language model (LM) adaptation and has attracted research interest for a long time. Latent Dirichlet Allocation (LDA), which assumes generative Dirichlet distribution with bag-of-word features for hidden topics, has been widely used as the state-of-the-art topic model. Inspired by recent development of a new paradigm of distributed paragraph representation called paragraph vector, a new topic model based on paragraph vector is proposed in this work. During training, each paragraph is mapped to a unique vector in continuous space. Then unsupervised clustering is performed to construct topic clusters. Topic-specific LM is then built based on clustering results. During adaptation, topic posterior is first estimated using the paragraph vector based topic model and new adapted LMs are constructed by interpolating the existing topic-specific models using topic posteriors. The proposed topic model is applied for LM adaptation and evaluated on Amazon Product Review Corpus for perplexity and a Chinese LVCSR task for CER evaluation. Results show that the proposed approach yields 11.1% relative perplexity reduction and 1.4% relative CER reduction over baseline, outperforming LDA based method proposed by previous work.

**Bio**: Wengong Jin is a senior student of ACM’12 Class. Currently he is a intern at Speech Lab, advised by Professor Kai Yu. His research interest lies in Natural Language Processing and Speech Recognition. Wengong will start his graduate study at MIT CSAIL next semester.

8.
**Title**: Collaborative Regret Minimization

**报告人**：刘爽（上海交通大学ACM班大四）

**Abstract**: We study a collaborative regret minimization problem where m players collaboratively play a stochastic multi-armed bandit game with d arms and try to minimize the total regret in n rounds. We show that the regret we can achieve depends on the bits of information that are allowed to be communicated through the network. Our main result relies on a tight regret bound which gives an exact characterization of the interplay between regret and the spacing of the communication rounds. To derive the results, we generalize the decomposition technique used in prior work and establish a novel technical lemma which may be of independent interest.

**Bio**: Shuang Liu is a senior student in ACM Honored Class. He is interested in theoretical aspects of machine learning.

9.
**Title**: Accelerating Random Kaczmarz Algorithm Based on Clustering Information

**报告人**：莫凯淳（上海交通大学ACM班大四）

**Abstract**: Kaczmarz algorithm is an efficient iterative algorithm to solve overdetermined consistent system of linear equations. During each updating step, Kaczmarz chooses a hyperplane based on an individual equation and projects the current estimate for the exact solution onto that space to get a new estimate. Many vairants of Kaczmarz algorithms are proposed on how to choose better hyperplanes. Using the property of randomly sampled data in high-dimensional space, we propose an accelerated algorithm based on clustering information to improve block Kaczmarz and Kaczmarz via Johnson-Lindenstrauss lemma. Additionally, we theoretically demonstrate convergence improvement on block Kaczmarz algorithm.

**Bio**: Kaichun Mo is a senior undergraduate student at 2012 ACM class and will join Stanford University as a Ph.D. student starting from 2016. His research interests focus on Computer Vision, Computer Graphics and Machine Learning. He join SJTU Learning and Optimization (LoG) Lab and work with Prof. Zhihua Zhang for two years and he also have an intern working with Prof. Kavita Bala at Cornell University.

10.
**Title**: ClickNP: Highly flexible and High-performance Network Processing with Reconfigurable Hardware

**报告人**：彭燕庆（上海交通大学ACM班大四）

**Abstract**: Highly flexible software network functions are critical components to enable multi-tenancy in cloud environments. However, software packet processing on a commodity server has limited capacity and induces high latency. While software network functions can be scaled out by using more servers, doing so adds significant cost. This paper targets to accelerate network functions with programmable hardware, i.e., FPGA, which is now a mature technology and inexpensive for datacenter deployment. However, FPGA is predominately programmed using low-level hardware description languages (HDL), which is hard to program and difficult to debug. More importantly, HDLs are almost not accessible for most software programmers. This paper presents ClickNP, a FPGA-accelerated platform for highly flexible and high-performance network functions with commodity servers. ClickNP is highly flexible as it is completely programmable using high-level C-like languages, and exposes a familiar modular programming abstraction that resembles Click Modular Router. ClickNP is high-performance. Our prototype network functions have shown that they can process traffic at up to 100 million packet per second with ultra-low latency (< 2 us). Compared to software network functions, with FPGA, ClickNP improves the throughput by 10x, but reduces the latency also by 10x. To the best of our knowledge, ClickNP is the first FPGA-accelerated packet processing platform, written completely in high-level language and achieving over 40~Gbps line rate at any packet size.

**Bio**: Yanqing Peng is a senior student of ACM Class' 12. He is a member of Advanced Networking Lab led by Prof. Fan Wu at Shanghai Jiao Tong University, and was a research intern in the Wireless and Networking Group led by Dr. Kun Tan at Microsoft Research Asia. He will start pursuing a Ph.D. degree at University of Utah from this August.

11.
**Title**: SLING: A Near-Optimal Index Structure for SimRank

**报告人**：田博雨（上海交通大学ACM班大四）

**Abstract**: SimRank is a similarity measure for graph nodes that has numerous applications in practice. Scalable SimRank computation has been the subject of extensive research for more than a decade, and yet, none of the existing solutions can efficiently derive SimRank scores on large graphs with provable accuracy guarantees. In particular, the state-of-the-art solution requires up to a few seconds to compute a SimRank score in million-node graphs, and does not offer any worst-case assurance in terms of the query error. This paper presents SLING, an efficient index structure for Sim-Rank computation. SLING guarantees that each SimRank score returned has at most ε additive error, and it answers any singlepair and single-source SimRank queries in O(1/ε) and O(n/ε)

time, respectively. These time complexities are near-optimal, and are significantly better than the asymptotic bounds of the most recent approach. Furthermore, SLING requires only O(n/ε) space

(which is also near-optimal in an asymptotic sense) and O(m/ε + n log nδ/ε2) pre-computation time, where δ is the failure probability of the preprocessing algorithm. We experimentally evaluate

SLING with a variety of real-world graphs with up to several millions of nodes. Our results demonstrate that SLING is up to 10000 times (resp. 110 times) faster than competing methods for singlepair (resp. single-source) SimRank queries, at the cost of higher space overheads.

**Bio**: Boyu Tian is a senior student of ACM class 2012. His research interest lies in the area of machine learning and database. He is going to start his PhD program in University of Michigan in the next fall.

12.
**Title**: DisturbLabel: Regularizing CNN on the Loss Layer

**报告人**：魏祯（上海交通大学ACM班大四）

**Abstract**: During a long period of time we are combating over-fitting in the CNN training process with model regularization, including weight decay, model averaging, data aug-mentation, etc. In this paper, we present DisturbLabel, an extremely simple algorithm which randomly replaces a part of labels as incorrect values in each iteration. Although it seems weird to intentionally generate incorrect training labels, we show that DisturbLabel prevents the network training from over-fitting by implicitly averaging over exponentially many networks which are trained with different label sets. To the best of our knowledge, DisturbLabel serves as the first work which adds noises on the loss layer. Meanwhile, DisturbLabel cooperates well with Dropout to provide complementary regularization functions. Experiments demonstrate competitive recognition results on several popular image recognition datasets.

**Bio**: Zhen Wei is a senior undergraduate student of ACM'12 Class. She spent her junior year in hashing for image retrieval following Prof. Hangtag Lu. After that, she begins to do research about deep neural network in computer vision with Dr. Jingdong Wang during her internship in MSRA.

13.
**Title**: From Collision To Exploitation: Unleashing Use-After-Free Vulnerabilities in Linux Kernel

**报告人**：许文（上海交通大学ACM班大四）

**Abstract**: In this work, we present a novel memory collision strategy to exploit the use-after-free vulnerabilities in Linux kernel reliably. The insight of our exploit strategy is that a probabilistic memory collision can be constructed according to the widely deployed kernel memory reuse mechanisms, which significantly increases the success rate of the attack. Based on this insight, we present two practical memory collision attacks: An object-based attack that leverages the memory recycling mechanism of the kernel allocator to achieve freed vulnerable object covering, and a physmap-based attack that takes advantage of the overlap between the physmap and the SLAB caches to achieve a more flexible memory manipulation. Our proposed attacks are universal for various Linux kernels of different architectures and can successfully exploit systems with use-after-free vulnerabilities in kernel. Particularly, we achieve privilege escalation on various popular Android devices (kernel version>=4.3) including those with 64-bit processors by exploiting CVE-2015-3636, a typical use-after-free vulnerability in Linux kernel. To our knowledge, this is the first generic kernel exploit for the latest version of Android. Finally, to defend this kind of memory collision, we propose two corresponding mitigation schemes.

**Bio**: Xu Wen is a senior student from ACM Class 2012. He researches system security and software security at Lab of Cryptology and Computer Security advised by Prof. Dawu Gu.

14.
**Title**: Event Detecting Algorithm based on Deep Learning

**报告人**：廖彤亮（上海交通大学ACM班大四）

**Abstract**: STRN (Spatial-Temporal Residual Network) is a state-of-art approach for video event detection and recognition. Based on the idea of Residual-Net, STRN uses a 36-layer CNN and a specially designed end-to-end training to achieve incredibly high accuracy on IXMAS multi-view human action dataset.

Training is done by SGD with a special phase called “Annealing”. The gradually increasing learning rate reduces the demand of BN (Batch Normalization) to squeeze out the last drop of performance. The simple end-to-end design makes it possible to serve as a frame/clip-level detector in 2D/2.5D (multi-view fusion) mode. No additional re-training is required. With well-optimized runtime, STRN can achieve real-time performance with both CPU/GPU on consumer grade desktop/laptop.

Here is the comparison between STRN and other state-of-art approaches on IXMAS. Clearly STRN has very competitive performance and has the least pre-assumptions as a pixel wise algorithm.

**Bio**: Liao, Tongliang is a senior student from ACM Class 2012. He researches system and deep learning at Lab of BCMI with professor Zhang, Liqing.
